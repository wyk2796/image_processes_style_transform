# coding:utf-8
import tensorflow as tf


def gram_matrix(x):
    assert tf.keras.backend.ndim(x) == 3
    features = tf.keras.backend.batch_flatten(tf.keras.backend.permute_dimensions(x, (2, 0, 1)))
    shape = tf.keras.backend.shape(x)
    C, W, H = (shape[0], shape[1], shape[2])
    cf = tf.keras.backend.reshape(features, (C, -1))
    gram = tf.keras.backend.dot(cf, tf.keras.backend.transpose(cf)) / tf.keras.backend.cast(C * W * H, dtype='float32')

    return gram


class StyleReconstructionRegularizer(tf.keras.regularizers.Regularizer):

    def __init__(self, style_feature_target, weight=1.0):
        self.style_feature_target = style_feature_target
        self.weight = weight
        self.uses_learning_phase = False
        super(StyleReconstructionRegularizer, self).__init__()
        self.style_gram = gram_matrix(style_feature_target)

    def __call__(self, x):
        output = x.output[0] # Generated by network
        loss = self.weight * tf.keras.backend.sum(
            tf.keras.backend.mean(tf.keras.backend.square((self.style_gram - gram_matrix(output)))))

        return loss


class FeatureReconstructionRegularizer(tf.keras.regularizers.Regularizer):

    def __init__(self, weight=1.0):
        self.weight = weight
        super(FeatureReconstructionRegularizer, self).__init__()

    def __call__(self, x):
        generated = x.output[0] # Generated by network features
        content = x.output[1] # True X input features

        loss = self.weight * tf.keras.backend.sum(tf.keras.backend.mean(tf.keras.backend.square(content-generated)))
        return loss


class TVRegularizer(tf.keras.regularizers.Regularizer):
    """ Enforces smoothness in image output. """

    def __init__(self, weight=1.0):
        self.weight = weight
        self.uses_learning_phase = False
        super(TVRegularizer, self).__init__()

    def __call__(self, x):
        assert tf.keras.backend.ndim(x.output) == 4
        x_out = x.output

        shape = tf.keras.backend.shape(x_out)
        img_width, img_height, channel = (shape[1], shape[2], shape[3])
        size = img_width * img_height * channel

        a = tf.keras.backend.square(x_out[:, :img_width - 1, :img_height - 1, :] - x_out[:, 1:, :img_height - 1, :])
        b = tf.keras.backend.square(x_out[:, :img_width - 1, :img_height - 1, :] - x_out[:, :img_width - 1, 1:, :])
        loss = self.weight * tf.keras.backend.sum(tf.keras.backend.pow(a + b, 1.25))
        return loss
